{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# 1- try directly giving mu and sigma\n",
    "# 2- try cnn vae\n",
    "# after convincing on the best approach\n",
    "# 3- discover label coded latent space (its evaluation for different beta)\n",
    "# 4- 2D manifold of digits (latent space=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# [0,255] -> [0,1]\n",
    "x_train = x_train/255.\n",
    "x_test = x_test/255.\n",
    "dataset_mean,dataset_std = np.mean(x_train),np.std(x_train)\n",
    "# standardization\n",
    "x_train = (x_train - dataset_mean) / (dataset_std)\n",
    "x_train = tf.keras.layers.Flatten()(x_train)\n",
    "x_test = (x_test - dataset_mean) / (dataset_std)\n",
    "x_test = tf.keras.layers.Flatten()(x_test)\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train))\n",
    "train_ds = train_ds.shuffle(1000).batch(64)\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = tf.reshape(x_test[:16],[-1,28,28])\n",
    "# destandardization\n",
    "preds = (preds * dataset_std) + dataset_mean\n",
    "preds = preds * 255.\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "for i in range(preds.shape[0]):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(preds[i, :, :], cmap='gray')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "# define encoder model\n",
    "inputs = tf.keras.Input(shape = (784,))\n",
    "x = tf.keras.layers.Dense(units=500, activation='relu')(inputs)\n",
    "x = tf.keras.layers.Dense(units=120, activation='relu')(x)\n",
    "mu = tf.keras.layers.Dense(units=latent_dim)(x)\n",
    "rho = tf.keras.layers.Dense(units=latent_dim)(x)\n",
    "Encoder = tf.keras.Model(inputs=inputs,outputs=[mu,rho])\n",
    "\n",
    "# define decoder model\n",
    "z = tf.keras.Input(shape = (latent_dim,))\n",
    "x = tf.keras.layers.Dense(units=120, activation='relu')(z)\n",
    "x = tf.keras.layers.Dense(units=500, activation='relu')(x)\n",
    "decoded_img = tf.keras.layers.Dense(units=784)(x)\n",
    "Decoder = tf.keras.Model(inputs=z,outputs=[decoded_img])\n",
    "\n",
    "class VAE(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder_block = Encoder\n",
    "        self.decoder_block = Decoder\n",
    "\n",
    "    def call(self,img):\n",
    "        z_mu,z_rho = self.encoder_block(img)\n",
    "\n",
    "        epsilon = tf.random.normal(shape=z_mu.shape,mean=0.0,stddev=1.0)\n",
    "        z = z_mu + tf.math.softplus(z_rho) * epsilon\n",
    "\n",
    "        decoded_img = self.decoder_block(z)\n",
    "\n",
    "        return z_mu,z_rho,decoded_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# closed form kl loss computation between variational posterior q(z|x) and unit Gaussian prior p(z) \n",
    "def kl_loss(z_mu,z_rho):\n",
    "    sigma_squared = tf.math.softplus(z_rho) ** 2\n",
    "    kl_1d = -0.5 * (1 + tf.math.log(sigma_squared) - z_mu ** 2 - sigma_squared)\n",
    "\n",
    "    # sum over sample dim, average over batch dim\n",
    "    kl_batch = tf.reduce_mean(tf.reduce_sum(kl_1d,axis=1))\n",
    "\n",
    "    return kl_batch\n",
    "\n",
    "def elbo(z_mu,z_rho,decoded_img,original_img):\n",
    "    # reconstruction loss\n",
    "    mse = tf.reduce_mean(tf.reduce_sum(tf.square(original_img - decoded_img),axis=1))\n",
    "    # kl loss\n",
    "    kl = kl_loss(z_mu,z_rho)\n",
    "\n",
    "    return mse,kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(model, epoch, step):\n",
    "  \n",
    "  # during prediction, sample from prior directly. 16 is batch size\n",
    "  z = tf.random.normal(shape=(16,model.encoder_block.output[0].shape[1]),mean=0.0,stddev=1.0)\n",
    "  preds = model.decoder_block(z)\n",
    "  preds = tf.reshape(preds,[-1,28,28])\n",
    "  # destandardization\n",
    "  preds = (preds * dataset_std) + dataset_mean\n",
    "  preds = preds * 255.\n",
    "\n",
    "  fig = plt.figure(figsize=(5, 5))\n",
    "  for i in range(preds.shape[0]):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(preds[i, :, :], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "  #plt.savefig(f'image_at_epoch_{epoch:04d}_step_{step:04d}.png')\n",
    "  plt.savefig(f'generated_samples.png')\n",
    "  #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_images(model, temp_x_train):\n",
    "\n",
    "  _,_,preds = model(temp_x_train)\n",
    "  preds = tf.reshape(preds,[-1,28,28])\n",
    "  # destandardization\n",
    "  preds = (preds * dataset_std) + dataset_mean\n",
    "  preds = preds * 255.\n",
    "\n",
    "  fig = plt.figure(figsize=(5, 5))\n",
    "  for i in range(preds.shape[0]):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(preds[i, :, :], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "  #plt.savefig(f'image_at_epoch_{epoch:04d}_step_{step:04d}.png')\n",
    "  plt.savefig(f'generated_test_samples.png')\n",
    "  #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "\n",
    "kl_loss_tracker = tf.keras.metrics.Mean(name='kl_loss')\n",
    "mse_loss_tracker = tf.keras.metrics.Mean(name='mse_loss')\n",
    "\n",
    "\n",
    "for epoch in range(100):\n",
    "\n",
    "    for step,imgs in train_ds.enumerate():\n",
    "        \n",
    "        # training loop\n",
    "        with tf.GradientTape() as tape:\n",
    "            # forward pass\n",
    "            z_mu,z_rho,decoded_imgs = model(imgs)\n",
    "\n",
    "            # compute loss\n",
    "            mse,kl = elbo(z_mu,z_rho,decoded_imgs,imgs)\n",
    "            loss = mse + 15. * kl\n",
    "\n",
    "        # compute gradients\n",
    "        gradients = tape.gradient(loss,model.variables)\n",
    "\n",
    "        # update weights\n",
    "        optimizer.apply_gradients(zip(gradients, model.variables))\n",
    "\n",
    "        # update metrics\n",
    "        kl_loss_tracker.update_state(kl)\n",
    "        mse_loss_tracker.update_state(mse)\n",
    "\n",
    "\n",
    "    # generate 16 samples every epoch.\n",
    "    generate_images(model,epoch,0)\n",
    "    generate_training_images(model, x_test[:16])\n",
    "\n",
    "    # display metrics at the end of each epoch.\n",
    "    epoch_kl,epoch_mse = kl_loss_tracker.result(),mse_loss_tracker.result()\n",
    "    print(f'epoch: {epoch}, mse: {epoch_mse:.4f}, kl_div: {epoch_kl:.4f}')\n",
    "\n",
    "    # reset metric states\n",
    "    kl_loss_tracker.reset_state()\n",
    "    mse_loss_tracker.reset_state()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a73d1662bd3aab4de55a1a51be85519c6e25d5d617da76d142a49d5ef38ee143"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch_tf_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
